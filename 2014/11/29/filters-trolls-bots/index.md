---
layout: oldpost
title: Filters, Trolls & Bots
date: 2014-11-29
excerpt_separator: <!--more-->
postFooter: Additional information?
---

The “real world,” we’re told, is an increasingly meaningless construct, a product of nostalgia or a failure to adapt to the digital age. Real life is no longer confined to face-to-face interactions, nor is identity constructed only there, but also on Facebook, Twitter, and in all the spaces that devices create by continuously talking to one another. While their forerunners were static, these environments are dynamic. We can still escape from reality in a book, a newspaper article or a movie, as passive spectators, but we actively create and influence the networks that compete for that same attention now. Thanks to mobile devices, moreover, we’re never simply immersed in the digital and away from the physical world around us—we comfortably occupy both at once. The term “meatspace” has thus become necessary as the distinction between real and virtual has vanished. If “real” things can happen in the digital sphere too, then environments are better characterized by their corporeality than by their realness.

Despite all the similarities, though, digital platforms differ from traditional reality in this respect: It’s too easy to leave them. A single mouse click makes Facebook or Twitter disappear, at least for a while, meaning they’re less enveloping than work, school, a social gathering, or any other meatspace activity that we wish we could exit as quickly. Unlike Amazon, who just want you to buy things, social networks like Facebook and Twitter need you to spend time using their platforms and plugging important parts of your life into them. Two thirds of Facebook’s 1.35 billion active users <a href="http://qz.com/288411/facebook-is-more-addictive-than-ever/">log in every day</a>, and Facebook’s future success depends on increasing that number. Since Facebook is competing with Twitter and other platforms for your time and attention, not to mention the possibility that you’ll put your computer away entirely, it becomes even more important to Facebook that you stay logged in.

<a href="https://kneelingbus.files.wordpress.com/2014/11/walking-through-walls-idf.jpg"><img class="aligncenter size-full wp-image-610" src="https://kneelingbus.files.wordpress.com/2014/11/walking-through-walls-idf.jpg" alt="walking-through-walls-idf" width="500" height="333" /></a>

<em>            Source: <a href="http://laudyms.wordpress.com/2011/04/06/walking-through-walls-israeli-idf-invasion-of-nablus/">laudyms.wordpress.com</a></em>

So, back to that big difference between digital reality and meatspace reality: How do we react when reality makes us feel bad? In the digital version, we tend to log off; in meatspace, we must react in ways that are rarely as simple—“dealing with it,” if you will. Twitter and Facebook both understand the low barriers to disengagement, and put significant effort into filtering the reality they present to their users. Twitter gives you full responsibility to choose who you follow, and empowers you to make unwanted voices disappear from your feed. Facebook’s solution is less transparent and more effective, judging by its growing addictiveness and nine-figure user base: Algorithms filter the content appearing in your News Feed, guessing what you want to see better than you could and hiding what you don’t like before you find out that it exists. On Twitter, in theory, you might follow accounts that you actively disagree with, but that’s doubtful in practice, and doing so would probably make you use Twitter less. If you could make that annoying coworker disappear with a single click, you probably would, right?

Filtering reality has long been a goal of environmental design. Before the internet, shopping malls and suburban enclaves were built to exclude undesirable elements, reinforce social myths, and make people feel good enough to not leave. Digital environments achieve those same objectives at greater scale and less expense. In 2012, Facebook <a href="https://medium.com/message/what-does-the-facebook-experiment-teach-us-c858c08e287f">conducted a controversial experiment</a> on a subset of users to better understand the emotional impact of its News Feed content and tune its algorithms accordingly. More recently, Adrian Chen <a href="http://www.wired.com/2014/10/content-moderation/">reported on Facebook’s overseas “content moderators”</a> who manually scan the network for offensive material and remove it before it appears in anyone’s feed. Both unsettling efforts, of course, aim to limit the negativity that Facebook’s users encounter on the site, maintain the network’s position as the ersatz spiritual center of contemporary life, and monetize that position as advertising revenue.

Like any designed environment, the internet’s largest platforms breed delinquent forces that actively subvert their designers’ goals. As if to remind us of the limitations of the social networks’ version of reality, two species have evolved and flourished in the digital ecosystem: the troll and the bot. Trolls—the antagonistic online personae of users who may actually be agreeable in person—distill the negativity that Twitter or Facebook make so much effort to hide, and exploit gaps in the networks’ sanitizing measures to force that negativity upon their chosen targets. Like barbarians or guerrilla combatants, their intimate familiarity with the landscape and their decentralized organization enables them to stay one step ahead of the countermeasures that an incumbent power employs to stop them (the blocking and muting features, account deactivation, or more sophisticated filtering algorithms). Trolls inhabit <a href="http://bldgblog.blogspot.com/2010/01/nakatomi-space.html">Nakatomi space</a> and make a mockery of the myth that multimillion-user networks can be scrubbed of unauthorized discourse. In their most extreme forms, trolls actually drive users away from their chosen social network altogether—and back to an environment where social norms and physical distance make trolling impossible.

https://twitter.com/Horse_ebooks/status/376447143709405184

Bots, less menacing than trolls and frequently even amusing, are also unwelcome in the digital landscape. Bots rarely represent real people, and thus expose the fallacy that social networks are places of firsthand human expression alone. Mining the internet for existing content, or posting according to programmed rules, bots add to <a href="http://www.ribbonfarm.com/2013/05/23/civilization-and-the-war-on-entropy/">the entropy that human work is always trying to reduce</a>. A sophisticated bot can nearly pass the <a href="http://en.wikipedia.org/wiki/Turing_test">Turing test</a> (or, in the case of <a href="https://twitter.com/horse_ebooks">@Horse_ebooks</a>, a human can pass for a bot imitating a human), revealing yet another advantage that meatspace still holds over social networks and dating websites: We’re still getting plenty of essential information from face-to-face interactions that can be faked or misinterpreted in digital channels. John Robb <a href="https://twitter.com/johnrobb/status/533659616606187520">has posited the future of Twitter</a> as machine conversations between bots, finding <a href="http://dweet.io/">one company</a> already pursuing that course. If users must wade through increasing volumes of digital noise to find the signals they’re looking for, they’ll revert to more familiar environments where it’s easy to distinguish the two.

Twitter has bigger problems with bots and trolls than Facebook does, suggesting that a truly free and transparent platform is impossible without the entropic tendencies that more controlled platforms can suppress. The very existence of trolls and bots, however, is a vaccine that inoculates us against a greater threat: Not understanding the digital landscape we spend so much time in, and imagining it’s governed by more familiar forces.