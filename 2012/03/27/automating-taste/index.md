---
layout: oldpost
title: Automating Taste
date: 2012-03-27
excerpt_separator: <!--more-->
postFooter: Additional information?
---

I haven’t seen many many TED Talks, but I can’t imagine that any are better than Kevin Slavin’s:

[youtube http://www.youtube.com/watch?v=TDaFwnOiKVE&w=560&h=315]

The precise meaning of “algorithm” is hard to pin down: Most simply, algorithms are sets of instructions, and could be executed with or without computers. A recipe is an algorithm. If I give you directions to my house, that’s an algorithm. Algorithms are, of course, central to mathematics, and executing increasingly complex algorithms is more or less why computers exist. But for most of human history, algorithms have served a primarily descriptive purpose, something Slavin suggests at 1:17 in his talk:

<em>“(Math) has transitioned from being something that we sort of extract and derive from the world, to something that actually starts to shape it—the world around us and the world inside us.” </em>

To illustrate his point, consider that primitive algorithm, the recipe. A recipe for meatloaf extracts and synthesizes certain properties of the physical world, yielding an output that a family could eat for dinner in 1950. If 100,000 families followed the same meatloaf recipe in 1950, that would have had little impact on how meatloaf was made or how many people wanted meatloaf in 1951. Today, though, algorithms work much faster and on much greater scales, and they have become much more ubiquitous. When you make a choice based upon what Netflix or Amazon recommend to you, that’s an outcome of an algorithm just like the meatloaf is, only you don’t get to see what goes into it, and by making the choice you have in turn influenced the algorithm. When you bake meatloaf for a different length of time than the recipe tells you to, the recipe doesn’t change in response to your decision.

When we tell the internet what we like, though, we influence what it will tell us. I have this idea for a novel, set in 2020, about a boy who accidentally listens to too many Coldplay songs on a Pandora-like site the first time he uses the internet and irrevocably distorts the algorithms’ assessment of him, dooming himself to a life of fourth-tier Britpop listening as he is fed more and more of the same. The culture algorithms to which Slavin alludes are so good at learning what we want and giving it to us that they ultimately determine what we want. A huge part of what we like is simply what we’re exposed to, after all. Slavin finally asks: How would we know if these algorithms that constitute the “physics of culture” failed, or crashed?

Last year, I wrote <a href="http://colabradio.mit.edu/dancing-lessons-from-god-peculiar-paths-from-a-to-b/">a post for MIT’s CoLab Radio blog</a> about Google Maps and the algorithms that determine our driving and walking routes. Google Maps assumes that everyone prefers the shortest path, an assumption that is usually but not always true. This algorithm attempts to model a basic human decision simplistically, and by becoming so widely used Google Maps‘ initial assumption has actually become more true. We now take the shortest path not because we want to (even if we do), but because Google Maps tells us to.

A fascinating side effect of many technological advances is that every new technology forces what it replaced to justify its value. The subtle advantages of analog music, fondness for album art and liner notes, and the joys of record store shopping were the features that MP3s could not offer; CDs and vinyl have reoriented to emphasize these features, as their other roles have been stripped away. An easy-to-find, major label CD without imaginative packaging will find few friends in the MP3-driven world. Telephones are another example. The land line, it turns out, offers almost nothing that mobile devices cannot do better, and land lines have begun to vanish accordingly.

Today, as algorithms become increasingly advanced, they perform more tasks that humans once did, and often much more effectively. Machines will continue to become more intelligent, and will simulate human behavior more convincingly. What we like and choose will increasingly be subject to algorithmic guidance. In many cases, we should be thankful: There are mundane decisions in life that I would gladly automate. Rather than ceding everything to the artificially intelligent, however, humans should focus on doing what they do best: being human. If a computer can identify email spam better than I can, I want it to do so, but I do not believe that a computer can decide what I like better than I can. Facing this possibility, we should decide which of our “features” truly make us human and aggressively defend them from algorithmic encroachment.